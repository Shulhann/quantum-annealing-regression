{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import *\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29386, 35)\n",
      "(7347, 35)\n",
      "(29386,)\n",
      "(7347,)\n"
     ]
    }
   ],
   "source": [
    "# Using Random Data\n",
    "# N = 100000                # Number of data\n",
    "# d = 2                     # Number of features\n",
    "# precision = 2             # Control precision bit of the output\n",
    "# dim = d * (2 * precision) # Size of the QUBO matrix\n",
    "# degree = 2                # Degree of the polynomial regression\n",
    "\n",
    "# # Generate Random Data\n",
    "# X = np.random.rand(N, d)\n",
    "# Y = np.random.rand(N)\n",
    "\n",
    "# Using Dataset\n",
    "start_time = time.time()\n",
    "\n",
    "dataset_path = 'dataset/processed dataset/dataset_6.csv'\n",
    "dataset_name = dataset_path.split('/')[-1]\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "Y = df.iloc[:, -1].values\n",
    "d = X.shape[1]\n",
    "precision = 3\n",
    "dim = d * (2 * precision)\n",
    "degree = 4\n",
    "\n",
    "# Train-Test data splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# If you want to perform polynomial regression\n",
    "X_train, d, dim = polynomialForm(X_train, d, dim, precision, degree)\n",
    "X_test, _, _ = polynomialForm(X_test, d, dim, precision, degree) \n",
    "\n",
    "end_time = time.time()\n",
    "preproccesing1_time = end_time - start_time\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPUTING SOME IMPORTANT VARIABLES\n",
    "Initiating variables that required to creating QUBO Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29386.         16240.93559752 15740.82719212 ...  4748.5355734\n",
      "   6657.27322622 10287.08274577]\n",
      " [16240.93559752  9839.55017915  8441.65442503 ...  2308.85304122\n",
      "   3285.0310112   5142.46091234]\n",
      " [15740.82719212  8441.65442503  8904.55036801 ...  2814.87266279\n",
      "   3742.88931846  5439.91433264]\n",
      " ...\n",
      " [ 4748.5355734   2308.85304122  2814.87266279 ...  1102.60693007\n",
      "   1487.24298553  2156.84788926]\n",
      " [ 6657.27322622  3285.0310112   3742.88931846 ...  1487.24298553\n",
      "   2156.84788926  3371.29197501]\n",
      " [10287.08274577  5142.46091234  5439.91433264 ...  2156.84788926\n",
      "   3371.29197501  5712.47370927]]\n",
      "[12370.8940614   6751.61819718  6712.30893073  8604.08434378\n",
      "  4078.83226244  3537.41697698  4492.56638704  3848.74957158\n",
      "  4666.15065447  6435.22677945  2656.50401791  2081.61407695\n",
      "  2588.65781347  1947.77399935  2357.22842287  3258.64856273\n",
      "  2318.54320802  2676.62069999  3479.26393627  5055.1772261\n",
      "  1828.77031963  1329.50744872  1609.39721586  1110.05413573\n",
      "  1323.67452725  1813.73658755  1122.47219002  1301.93487807\n",
      "  1707.76820845  2505.14945412  1461.53747069  1613.57911757\n",
      "  1990.97950252  2720.88104098  4113.59987604]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "XtX = np.matmul(X_train.T, X_train) # Covariance matrix\n",
    "XtY = np.matmul(X_train.T, Y_train) # Relation between Features and Y\n",
    "\n",
    "end_time = time.time()\n",
    "preproccesing2_time = end_time - start_time\n",
    "\n",
    "print(XtX)\n",
    "print(XtY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preproccesing_time = preproccesing1_time + preproccesing2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIXSTAR AMPLIFY SIMULATED ANNEALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model = generateQuboMatrix_fixstar(XtX, XtY, dim, precision, d)\n",
    "end_time = time.time()\n",
    "fixstar_preproccesing_time = end_time - start_time + total_preproccesing_time\n",
    "\n",
    "start_time = time.time()\n",
    "sampleset_fixstar = sampling_fixstar(model)\n",
    "end_time = time.time()\n",
    "fixstar_execution_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "distributions_fixstar, weights_fixstar = solve_fixstar(sampleset_fixstar, dim, precision, d)\n",
    "end_time = time.time()\n",
    "fixstar_postproccesing_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixstar Training Evaluation:\n",
      "MSE: 0.03583, MAE: 0.14857, R²: 0.07239\n",
      "\n",
      "Fixstar Testing Evaluation:\n",
      "MSE: 0.03573, MAE: 0.14798, R²: 0.07375\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred_fixstar = np.dot(X_train, weights_fixstar)\n",
    "Y_test_pred_fixstar = np.dot(X_test, weights_fixstar)\n",
    "\n",
    "# Evaluate on training data\n",
    "train_mse_fixstar = mean_squared_error(Y_train, Y_train_pred_fixstar)\n",
    "train_mae_fixstar = mean_absolute_error(Y_train, Y_train_pred_fixstar)\n",
    "train_r2_fixstar = r2_score(Y_train, Y_train_pred_fixstar) \n",
    "\n",
    "# Evaluate on test data\n",
    "test_mse_fixstar = mean_squared_error(Y_test, Y_test_pred_fixstar)\n",
    "test_mae_fixstar = mean_absolute_error(Y_test, Y_test_pred_fixstar)\n",
    "test_r2_fixstar = r2_score(Y_test, Y_test_pred_fixstar)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Fixstar Training Evaluation:\")\n",
    "print(f\"MSE: {train_mse_fixstar:.5f}, MAE: {train_mae_fixstar:.5f}, R²: {train_r2_fixstar:.5f}\")    \n",
    "\n",
    "print(\"\\nFixstar Testing Evaluation:\")\n",
    "print(f\"MSE: {test_mse_fixstar:.5f}, MAE: {test_mae_fixstar:.5f}, R²: {test_r2_fixstar:.5f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEAL SIMULATED ANNEALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "Q = generateQuboMatrix_neal(XtX, XtY, precision, d)\n",
    "end_time = time.time()\n",
    "neal_preproccesing_time = end_time - start_time + total_preproccesing_time\n",
    "\n",
    "start_time = time.time()\n",
    "sampleset_neal = sampling_neal(Q)\n",
    "end_time = time.time()\n",
    "neal_execution_time = end_time - start_time \n",
    "\n",
    "start_time = time.time()\n",
    "distributions_neal, weights_neal = solve_neal(sampleset_neal, dim, precision, d)\n",
    "end_time = time.time()\n",
    "neal_postproccesing_time = end_time - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neal Training Evaluation:\n",
      "MSE: 0.04139, MAE: 0.16127, R²: -0.07174\n",
      "\n",
      "Neal Testing Evaluation:\n",
      "MSE: 0.04097, MAE: 0.15922, R²: -0.06196\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred_neal = np.dot(X_train, weights_neal)\n",
    "Y_test_pred_neal = np.dot(X_test, weights_neal)\n",
    "\n",
    "# Evaluate on training data\n",
    "train_mse_neal = mean_squared_error(Y_train, Y_train_pred_neal)\n",
    "train_mae_neal = mean_absolute_error(Y_train, Y_train_pred_neal)\n",
    "train_r2_neal = r2_score(Y_train, Y_train_pred_neal)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_mse_neal = mean_squared_error(Y_test, Y_test_pred_neal)\n",
    "test_mae_neal = mean_absolute_error(Y_test, Y_test_pred_neal)\n",
    "test_r2_neal = r2_score(Y_test, Y_test_pred_neal)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Neal Training Evaluation:\")\n",
    "print(f\"MSE: {train_mse_neal:.5f}, MAE: {train_mae_neal:.5f}, R²: {train_r2_neal:.5f}\")\n",
    "\n",
    "print(\"\\nNeal Testing Evaluation:\")\n",
    "print(f\"MSE: {test_mse_neal:.5f}, MAE: {test_mae_neal:.5f}, R²: {test_r2_neal:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SCIKIT LEARN (TRADISIONAL WAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 6.90535756e-13  2.43077632e+01  1.74794574e+01  9.77929268e-01\n",
      " -5.28776706e+01 -5.36306701e+01 -1.73098515e+00 -2.75883308e+01\n",
      " -4.85099290e+00 -2.49131882e+00  4.64934102e+01  6.46823799e+01\n",
      "  8.84037032e+00  4.84549501e+01  2.59034445e+00 -1.19181831e-01\n",
      "  2.40697343e+01 -5.65777627e-01  8.01330010e+00  1.27181337e+00\n",
      " -1.38599705e+01 -2.62241584e+01 -5.70745544e+00 -2.21363308e+01\n",
      " -1.00107123e+01  3.17960255e+00 -2.21770658e+01  8.09512200e+00\n",
      " -1.44015104e+00 -3.00126488e+00 -8.61277261e+00  4.21123067e+00\n",
      " -7.30637034e+00 -7.92830851e-01  4.47695577e-01]\n",
      "Fixstar Training Evaluation:\n",
      "MSE: 0.03545, MAE: 0.14747, R²: 0.08223\n",
      "\n",
      "Fixstar Testing Evaluation:\n",
      "MSE: 0.03537, MAE: 0.14693, R²: 0.08315\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Coefficients:\", clf.coef_)\n",
    "\n",
    "Y_train_pred_sklearn = clf.predict(X_train)\n",
    "Y_test_pred_sklearn = clf.predict(X_test)\n",
    "\n",
    "# Evaluate on training data\n",
    "train_mse_sklearn = mean_squared_error(Y_train, Y_train_pred_sklearn)\n",
    "train_mae_sklearn = mean_absolute_error(Y_train, Y_train_pred_sklearn)\n",
    "train_r2_sklearn = r2_score(Y_train, Y_train_pred_sklearn) \n",
    "\n",
    "# Evaluate on test data\n",
    "test_mse_sklearn = mean_squared_error(Y_test, Y_test_pred_sklearn)\n",
    "test_mae_sklearn = mean_absolute_error(Y_test, Y_test_pred_sklearn)\n",
    "test_r2_sklearn = r2_score(Y_test, Y_test_pred_sklearn)\n",
    "\n",
    "end_time = time.time()  \n",
    "sklearn_execution_time = end_time - start_time\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Fixstar Training Evaluation:\")\n",
    "print(f\"MSE: {train_mse_sklearn:.5f}, MAE: {train_mae_sklearn:.5f}, R²: {train_r2_sklearn:.5f}\")    \n",
    "\n",
    "print(\"\\nFixstar Testing Evaluation:\")\n",
    "print(f\"MSE: {test_mse_sklearn:.5f}, MAE: {test_mae_sklearn:.5f}, R²: {test_r2_sklearn:.5f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VISUALIZATION OF GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the graph and add all nodes first\n",
    "# G = nx.Graph()\n",
    "# nodes = set()\n",
    "# for (i, j) in Q.keys():\n",
    "#     nodes.add(i)\n",
    "#     nodes.add(j)\n",
    "# G.add_nodes_from(nodes)\n",
    "\n",
    "# # Now add edges and node attributes\n",
    "# for (i, j), weight in Q.items():\n",
    "#     if weight != 0 and i <= j:  # Avoid duplicates and zero-weights\n",
    "#         if i == j:\n",
    "#             G.nodes[i]['bias'] = weight  # Now safe because node exists\n",
    "#         else:\n",
    "#             G.add_edge(i, j, weight=weight)\n",
    "\n",
    "# # Visualization\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# pos = nx.circular_layout(G)\n",
    "\n",
    "# # Draw nodes and edges\n",
    "# nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=800)\n",
    "# nx.draw_networkx_labels(G, pos, font_size=12)\n",
    "\n",
    "# # Scale edge widths by absolute weight\n",
    "# max_weight = max(abs(d['weight']) for _, _, d in G.edges(data=True))\n",
    "# edge_widths = [0.1 + 2 * abs(G[u][v]['weight']) / max_weight for u, v in G.edges()]\n",
    "# nx.draw_networkx_edges(G, pos, width=edge_widths, edge_color='gray')\n",
    "\n",
    "# # Add edge labels (rounded)\n",
    "# edge_labels = {(u, v): f\"{d['weight']:.1f}\" for u, v, d in G.edges(data=True)}\n",
    "# nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "# # Add node biases\n",
    "# for node, (x, y) in pos.items():\n",
    "#     bias = G.nodes[node].get('bias', 0)\n",
    "#     plt.text(x, y-0.1, f\"bias={bias:.1f}\", ha='center', fontsize=8, color='red')\n",
    "\n",
    "# plt.title(\"QUBO Graph (Edge Width ∝ |Weight|)\", fontsize=14)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = nx.spring_layout(G, k=0.5, weight='weight', iterations=100)\n",
    "# nx.draw(G, pos, with_labels=True, \n",
    "#        node_color='lightblue', node_size=800,\n",
    "#        width=[0.1 + 2*abs(G[u][v]['weight'])/max_weight for u,v in G.edges()],\n",
    "#        edge_color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# pos = nx.spring_layout(G, dim=3, weight='weight')\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# for u, v in G.edges():\n",
    "#     ax.plot([pos[u][0], pos[v][0]], \n",
    "#             [pos[u][1], pos[v][1]], \n",
    "#             [pos[u][2], pos[v][2]], \n",
    "#             'gray')\n",
    "# ax.scatter(*np.array(list(pos.values())).T, s=100, c='lightblue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINAL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Number of Row</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Number_Of_Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset_split</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>preproccesing_time</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>postproccesing_time</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset_6.csv</td>\n",
       "      <td>36733</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Neal</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.161274</td>\n",
       "      <td>-0.071740</td>\n",
       "      <td>0.063122</td>\n",
       "      <td>0.419859</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.493441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset_6.csv</td>\n",
       "      <td>36733</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Neal</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.040970</td>\n",
       "      <td>0.159219</td>\n",
       "      <td>-0.061961</td>\n",
       "      <td>0.063122</td>\n",
       "      <td>0.419859</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.493441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset_6.csv</td>\n",
       "      <td>36733</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Fixstar</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.035828</td>\n",
       "      <td>0.148573</td>\n",
       "      <td>0.072389</td>\n",
       "      <td>0.140224</td>\n",
       "      <td>5.825801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.966025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset_6.csv</td>\n",
       "      <td>36733</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Fixstar</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.147978</td>\n",
       "      <td>0.073754</td>\n",
       "      <td>0.140224</td>\n",
       "      <td>5.825801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.966025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset_6.csv</td>\n",
       "      <td>36733</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Sklearn</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.035448</td>\n",
       "      <td>0.147472</td>\n",
       "      <td>0.082231</td>\n",
       "      <td>-</td>\n",
       "      <td>0.022553</td>\n",
       "      <td>-</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset_6.csv</td>\n",
       "      <td>36733</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Sklearn</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>0.146933</td>\n",
       "      <td>0.083149</td>\n",
       "      <td>-</td>\n",
       "      <td>0.022553</td>\n",
       "      <td>-</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset_Name  Number of Row  Precision  Degree  Number_Of_Features  \\\n",
       "0  dataset_6.csv          36733          3       4                  35   \n",
       "1  dataset_6.csv          36733          3       4                  35   \n",
       "2  dataset_6.csv          36733          3       4                  35   \n",
       "3  dataset_6.csv          36733          3       4                  35   \n",
       "4  dataset_6.csv          36733          3       4                  35   \n",
       "5  dataset_6.csv          36733          3       4                  35   \n",
       "\n",
       "     Model Dataset_split       MSE       MAE  R2 Score preproccesing_time  \\\n",
       "0     Neal         Train  0.041394  0.161274 -0.071740           0.063122   \n",
       "1     Neal          Test  0.040970  0.159219 -0.061961           0.063122   \n",
       "2  Fixstar         Train  0.035828  0.148573  0.072389           0.140224   \n",
       "3  Fixstar          Test  0.035734  0.147978  0.073754           0.140224   \n",
       "4  Sklearn         Train  0.035448  0.147472  0.082231                  -   \n",
       "5  Sklearn          Test  0.035372  0.146933  0.083149                  -   \n",
       "\n",
       "   execution_time postproccesing_time  total_time  \n",
       "0        0.419859            0.010459    0.493441  \n",
       "1        0.419859            0.010459    0.493441  \n",
       "2        5.825801                 0.0    5.966025  \n",
       "3        5.825801                 0.0    5.966025  \n",
       "4        0.022553                   -    0.022553  \n",
       "5        0.022553                   -    0.022553  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Dataset_Name\": [dataset_name] * 6,\n",
    "    \"Number of Row\": [df.shape[0]] * 6,  \n",
    "    \"Precision\": [precision] * 6,\n",
    "    \"Degree\": [degree] * 6,\n",
    "    \"Number_Of_Features\": [d] * 6,\n",
    "    \"Model\": [\"Neal\", \"Neal\", \"Fixstar\", \"Fixstar\", \"Sklearn\", \"Sklearn\"],\n",
    "    \"Dataset_split\": [\"Train\", \"Test\", \"Train\", \"Test\", \"Train\", \"Test\"],\n",
    "    \"MSE\": [\n",
    "        train_mse_neal, test_mse_neal,\n",
    "        train_mse_fixstar, test_mse_fixstar,\n",
    "        train_mse_sklearn, test_mse_sklearn\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        train_mae_neal, test_mae_neal,\n",
    "        train_mae_fixstar, test_mae_fixstar,\n",
    "        train_mae_sklearn, test_mae_sklearn\n",
    "    ],\n",
    "    \"R2 Score\": [\n",
    "        train_r2_neal, test_r2_neal,\n",
    "        train_r2_fixstar, test_r2_fixstar,\n",
    "        train_r2_sklearn, test_r2_sklearn\n",
    "    ],\n",
    "    \"preproccesing_time\": [\n",
    "        neal_preproccesing_time, neal_preproccesing_time,\n",
    "        fixstar_preproccesing_time, fixstar_preproccesing_time,\n",
    "        \"-\", \"-\" \n",
    "    ],\n",
    "    \"execution_time\": [\n",
    "        neal_execution_time, neal_execution_time,\n",
    "        fixstar_execution_time, fixstar_execution_time,\n",
    "        sklearn_execution_time, sklearn_execution_time\n",
    "    ],\n",
    "    \"postproccesing_time\": [\n",
    "        neal_postproccesing_time, neal_postproccesing_time,\n",
    "        fixstar_postproccesing_time, fixstar_postproccesing_time,\n",
    "        \"-\", \"-\"\n",
    "    ],\n",
    "    \"total_time\": [\n",
    "        neal_preproccesing_time + neal_execution_time + neal_postproccesing_time,neal_preproccesing_time + neal_execution_time + neal_postproccesing_time,\n",
    "        fixstar_preproccesing_time + fixstar_execution_time + fixstar_postproccesing_time,fixstar_preproccesing_time + fixstar_execution_time + fixstar_postproccesing_time,\n",
    "        sklearn_execution_time, sklearn_execution_time\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_eval = pd.DataFrame(data)\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully appended to Excel file.\n"
     ]
    }
   ],
   "source": [
    "excel_filename = \"evaluation_results2.xlsx\"\n",
    "\n",
    "# Add new data\n",
    "append_to_excel_enhanced(\n",
    "    excel_filename,\n",
    "    df_eval,\n",
    "    check_columns=['Dataset_Name', 'Precision', 'Degree']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
